{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# NLP Final Presentation - Airline Tweets LDA Model Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Negative Topic Categorization\n",
    "- Topic 1 --> Delay and Customer Service\n",
    "- Topic 2 --> Baggage Issue\n",
    "- Topic 3 --> Reschedule and Refund\n",
    "- Topic 4 --> Phone and Online Booking\n",
    "- Topic 5 --> Reservation Issue\n",
    "- Topic 6 --> Seating Preferences\n",
    "- Topic 7 --> Extra Charges\n",
    "- Topic 8 --> Customer Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_topic(tweet):\n",
    "    from ipywidgets import interact\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.pipeline import FeatureUnion\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    from os import path\n",
    "    from wordcloud import WordCloud, STOPWORDS \n",
    "    from PIL import Image\n",
    "    from wordcloud import ImageColorGenerator\n",
    "    import re\n",
    "\n",
    "    import pickle\n",
    "    import joblib\n",
    "    import spacy\n",
    "\n",
    "    import re\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    #nltk.download('wordnet')\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    import string\n",
    "    import numpy as np\n",
    "    #nltk.download('punkt')\n",
    "    from nltk import word_tokenize,sent_tokenize\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from textblob import TextBlob\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    import datetime\n",
    "    import warnings\n",
    "    import gensim\n",
    "    from gensim.utils import simple_preprocess\n",
    "    from gensim.parsing.preprocessing import STOPWORDS\n",
    "    from bs4 import BeautifulSoup\n",
    "    from gensim.models import CoherenceModel\n",
    "    from gensim import corpora, models\n",
    "\n",
    "    lda_model4=models.LdaModel.load('/Users/jenniferwu/Desktop/MSBA/Spring 2020/NLP/final project/lda_model4.model')\n",
    "\n",
    "    #preprocess data\n",
    "    def preprocess(text):\n",
    "        stopwords = set(STOPWORDS)\n",
    "        stopwords.update([\"american\", \"air\",\"airline\",\"thank\",\"united\",\"us\",\"airways\",\"virgin\",\"america\",\"jetblue\",\"youre\",\"extremely\",\n",
    "                     \"usairway\",\"usairways\",\"flight\",\"americanair\",\"southwestair\",\"southwestairlines\",\"arbitrarily\",\"dream\",\"crazy\",\n",
    "                     \"southwestairway\",\"southwestairways\",\"virginamerica\",\"really\",\"will\",\"going\",\"thanks\",\"thankyou\",\"passengersdont\",\n",
    "                     \"please\",\"got\",\"let\",\"take\",\"help\",\"already\",\"never\",\"now\",\"told\",\"guy\",\"new\",\"sure\",\"still\",\"amp\",\"continue\",\n",
    "                     \"plane\",\"tell\",\"ye\",\"trying\",\"yes\",\"guy\",\"much\",\"appreciate\", \"thx\",\"back\",\"ok\",\"good\",\"credit\",\"aacom\",\n",
    "                     \"flying\",\"love\",\"great\",\"awesome\",\"see\",\"nice\",\"alway\",\"httptcojwl26g6lrw\",\"dontflythem\",\"motherinlaw\",\"night\",\n",
    "                     \"nogearnotraining\",\"seriously\",\"didnt\",\"coudnt\",\"cant\",\"wont\",\"dont\",\"wat\",\"buffaloniagara\",\"hasshe\",\"morning\",\n",
    "                     \"woulda\",\"people\",\"try\",\"youve\",\"youd\",\"yours\",\"flightled\",\"tomorrow\",\"today\",\"wat\",\"jfkyou\",\"flite\",\"cause\",\n",
    "                     \"flightr\",\"flight\",\"need\",\"hours\",\"nooooo\",\"like\",\"doesnt\",\"right\",\"talk\",\"tweet\",\"mention\",\"pbijfk\",\"ridiculuous\",\n",
    "                     \"wasnt\",\"suppose\",\"want\",\"understand\",\"come\",\"work\",\"worse\",\"treat\",\"think\",\"know\",\"worst\",\"paulo\",\"staduim\",\n",
    "                     \"wouldnt\",\"stay\",\"away\",\"wont\",\"werent\",\"happen\",\"sorry\",\"havent\",\"tonight\",\"drive\",\"life\",\"thing\",\"aa951\",\n",
    "                     \"whats\",\"theyre\",\"better\",\"thats\",\"allow\",\"hope\",\"stop\",\"cool\",\"niece\",\"happy\",\"word\",\"customercant\",\n",
    "                     \"suck\",\"sunday\",\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"weekend\",\"ruin\",\"shouldnt\",\n",
    "                     \"miami\",\"los angeles\",\"new york\",\"chicago\",\"dallas\",\"apparently\",\"itover\",\"someones\",\"savannah\",\"lucymay\",\n",
    "                     \"betterother\",\"instead\",\"look\",\"hopefully\",\"yesterday\",\"antonio\",\"unacceptable\",\"folks\",\"record\",'arent',\n",
    "                     \"miss\",\"hang\",\"wrong\",\"stick\",\"grind\",\"tarmac\",\"theres\",\"forget\",\"terrible\",\"clothe\",\"terrible\",\"break\",\n",
    "                     \"actually\",\"frustrate\",\"correct\",\"ridiculous\",\"expect\",\"different\",\"pathetic\",\"bother\",\"follow\",\"fault\",\n",
    "                     \"impossible\",\"point\",\"cover\",\"person\",\"ask\",\"speak\",\"things\",\"earlier\",\"mean\",\"select\",\"minutes\",\n",
    "                     \"unite\",\"horrible\",\"country\",\"leave\",\"speak\",\"apologize\",\"faster\",\"hop\",\"confuse\",\"lose\",\"flightd\",\"hear\",\n",
    "                     \"literally\",\"years\",\"surprise\",\"bump\",\"fail\",\"compensate\",\"hand\",\"helpful\",\"upset\",\"friend\",\"excuse\",\"claim\",\n",
    "                     \"situation\",\"multiple\",\"weather\",\"choose\",\"company\",\"believe\",\"question\",\"kick\",\"anymore\",\"awful\",\"delta\",\n",
    "                      \"dozen\",\"medical\",\"completely\",\"finally\", \"waste\",\"shock\",\"annoy\",\"maybe\",\"strand\",\"mess\",\"finally\",\n",
    "                      \"plan\",\"place\",\"apology\",\"center\",\"plan\",\"twitter\",\"promise\",\"prefer\",\"count\",\"maybe\",\"shock\",\"longer\",\"meet\",\n",
    "                         \"important\",\"drop\"])\n",
    "        #stopwords.update([i for i in ts])\n",
    "        # stopwords.update([str(i).lower() for i in cities.City]) #removing City names in US\n",
    "        r = re.compile(r'(?<=\\@)(\\w+)') #remove words after tags --> usually twitter account\n",
    "        ra = re.compile(r'(?<=\\#)(\\w+)') #remove words after hashtags\n",
    "        ro = re.compile(r'(flt\\d*)') #remove words after flight number\n",
    "        names = r.findall(text.lower())\n",
    "        hashtag = ra.findall(text.lower())\n",
    "        flight = ro.findall(text.lower())\n",
    "        lmtzr = WordNetLemmatizer()\n",
    "        def stem_tokens(tokens, lemmatize):\n",
    "            lemmatized = []\n",
    "            for item in tokens:\n",
    "                lemmatized.append(lmtzr.lemmatize(item,'v'))\n",
    "            return lemmatized\n",
    "        def deEmojify(inputString):\n",
    "            return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "        #doc = nlp(text)\n",
    "        text = deEmojify(text)\n",
    "        soup = BeautifulSoup(text)\n",
    "        text = soup.get_text()\n",
    "        text = \"\".join([ch.lower() for ch in text if ch not in string.punctuation])\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [ch for ch in tokens if len(ch)>4] #remove words with character length below 2\n",
    "        tokens = [ch for ch in tokens if len(ch)<=15] #remove words with character length above 15 \n",
    "        lemm = stem_tokens(tokens, lmtzr)\n",
    "        lemstop = [i for i in lemm if i not in stopwords]\n",
    "        lemstopcl = [i for i in lemstop if i not in names]\n",
    "        lemstopcl = [i for i in lemstopcl if i not in hashtag]\n",
    "        lemstopcl = [i for i in lemstopcl if i not in flight]\n",
    "        lemstopcl = [i for i in lemstopcl if not i.isdigit()]\n",
    "        #lemstopcl1 = [i for i in lemstopcl if i not in t]\n",
    "        return lemstopcl\n",
    "\n",
    "    \n",
    "    \n",
    "    id2word = corpora.Dictionary.load('id2word.dict')\n",
    "\n",
    "    bow_vector = id2word.doc2bow(preprocess(tweet))\n",
    "    result = lda_model4.get_document_topics(bow_vector)\n",
    "    resultdict = dict(result)\n",
    "    orddict = sorted(resultdict, key=resultdict.get, reverse=True)\n",
    "    \n",
    "    Keymax = 1\n",
    "    if resultdict[orddict[0]]-resultdict[orddict[1]] <=.08:\n",
    "        Keymax +=orddict[1]\n",
    "        print(\"Predicted topic: \",orddict[1]+1)\n",
    "        print(\"Probability Score: \",resultdict[orddict[0]])\n",
    "    else:\n",
    "        Keymax +=orddict[0]\n",
    "        print(\"Predicted topic: \",orddict[0]+1)\n",
    "        print(\"Probability Score: \",resultdict[orddict[0]])\n",
    "\n",
    "\n",
    "    if Keymax == 1:\n",
    "        print('Delay and Customer Service')\n",
    "    elif Keymax == 2:\n",
    "        print('Baggage Issue')\n",
    "    elif Keymax == 3:\n",
    "        print('Reschedule and Refund')\n",
    "    elif Keymax == 4:\n",
    "        print('Phone and Online Booking')\n",
    "    elif Keymax == 5:\n",
    "        print('Reservation Issue')\n",
    "    elif Keymax == 6:\n",
    "        print('Seating Preferences')\n",
    "    elif Keymax == 7:\n",
    "        print('Extra Charges')\n",
    "    else:\n",
    "        print('Customer Experience')\n",
    "    print(\"\\n\")\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(resultdict.items())\n",
    "    df[0]=df[0]+1\n",
    "    \n",
    "    if Keymax==orddict[1]+1: \n",
    "        temp=df.iloc[orddict[0],1]\n",
    "        df.iloc[orddict[0],[1]]=df.iloc[Keymax-1,1]\n",
    "        df.iloc[Keymax-1,[1]]=temp\n",
    "    else:\n",
    "        df[1]=df[1]\n",
    "    \n",
    "    %matplotlib inline\n",
    "    colors =  ['#3f5994','#8cbcfb','#c9e5fa','#f4dad0',\"#f8bc99\",'#f3aa84', '#f49c6c',\"#c48771\"]\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.title(\"Topic Probability Score\",size=48)\n",
    "    plt.xticks(rotation= 20, size=30)\n",
    "    plt.yticks(size=30)\n",
    "    ax = sns.barplot(x=df[0],y=df[1],palette=colors)\n",
    "    plt.ylabel('Probability Score', fontsize=35)\n",
    "    plt.xlabel('Topics', fontsize=35)\n",
    "    plt.show()\n",
    "    \n",
    "    for index, score in resultdict.items():\n",
    "        print(\"Score: {}\\n Topic: {}\\n Keywords:{} \\n\".format(score, index+1, lda_model4.print_topic(index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c47cc75c5ac422daa5813fe0e4369aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='abcd', description='tweet'), Button(description='Run Interact', style=Buttonâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.predict_topic(tweet)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "interact_manual(predict_topic, tweet='abcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
